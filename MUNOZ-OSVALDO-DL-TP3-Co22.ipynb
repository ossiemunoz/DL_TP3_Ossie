{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc8f759",
   "metadata": {},
   "source": [
    "# Universidad de Buenos Aires\n",
    "\n",
    "## Aprendizaje Profundo - TP3\n",
    "## Cohorte 22 - 5to bimestre 2025\n",
    "\n",
    "### Profesor: Esp. Ing. Gerardo Vilcamiza\n",
    "### Alumno: Osvaldo Daniel Muñoz - SIU a2222\n",
    "\n",
    "> **Formato de entrega:** un único notebook de Google Colab. Renombrar así: `MUNOZ-OSVALDO-DL-TP3-Co22.ipynb`.\n",
    "> **Compartir con:** `gvilcamiza.ext@fi.uba.ar` con permisos de **comentador**.\n",
    "\n",
    "Este notebook se puede ejecutar indistintamente en VS Code y en Colab.\n",
    "Incluye:\n",
    "- Las secciones y celdas ya organizadas por consigna.\n",
    "- Cargar el dataset de imágenes en el entorno de Colab antes de ejecutar: (https://drive.google.com/file/d/1aPHE00zkDhEV1waJKhaOJMdN6-lUc0iT/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc329c",
   "metadata": {},
   "source": [
    "### Objetivo general:\n",
    "\n",
    "El objetivo de este trabajo es construir una red neuronal convolucional (CNN) utilizando Pytorch, capaz de clasificar emociones humanas a partir de imágenes faciales. El clasificador deberá identificar una de las 7 emociones básicas: alegría, tristeza, enojo, miedo, sorpresa, disgusto y seriedad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0fd3e",
   "metadata": {},
   "source": [
    "### Punto 1. Preprocesamiento de Datos (2 puntos)\n",
    "Antes de entrenar el modelo, se debe analizar qué tipo de preprocesamiento se debe aplicar a las imágenes. Para esto, se puede considerar uno o más aspectos como:\n",
    "\n",
    "- Tamaño\n",
    "- Relación de aspecto\n",
    "- Color o escala de grises\n",
    "- Cambio de dimensionalidad\n",
    "- Normalización\n",
    "- Balanceo de datos\n",
    "- Data augmentation\n",
    "\n",
    "Ser criteriosos y elegir solo las técnicas que consideren pertinentes para este caso de uso en específico.\n",
    "\n",
    "Recomendación: usar torchvision.transforms para facilitar el preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb904e7a",
   "metadata": {},
   "source": [
    "### Planteamiento inicial:\n",
    "\n",
    "Para este trabajo analizaremos las características del dataset provisto, compuesto por imágenes de 100×100 píxeles, profundidad de color de 24 bits y distribución homogénea en RGB. Dado que el objetivo final incluye evaluar el modelo con imágenes externas (descargadas o tomadas de otras fuentes), se decide mantener la representación en RGB, evitando conversiones a escala de grises evitando eliminar información relevante sobre sombras y matices presentes en las imágenes reales.\n",
    "\n",
    "Las imágenes fueron redimensionadas a un tamaño fijo de 100×100 píxeles, respetando la dimensionalidad original del dataset para evitar distorsiones y para mantener consistencia entre el conjunto de entrenamiento, validación y las imágenes externas utilizadas en pruebas adicionales.\n",
    "\n",
    "Posteriormente aplicaremos normalización por canal, utilizando los valores estándar de ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), lo cual facilita la estabilidad numérica durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP / IMPORTS / CONFIGURACIONES GENERALES\n",
    "\n",
    "import os\n",
    "# PyTorch\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# estilos para los plots\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Mayor estabilidad a costa de velocidad en GPU\n",
    "DETERMINISTIC = True\n",
    "\n",
    "if DETERMINISTIC:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device (CPU/GPU) según disponibilidad\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMACIONES\n",
    "\n",
    "# Para entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),  # mantiene formato original del dataset\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # valores estándar RGB\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Para validación / test\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# ===========================\n",
    "# DATASETS\n",
    "# ===========================\n",
    "\n",
    "train_dir = \"/home/ossiemunoz/projects/DL_TP3/dataset_emociones/train\"\n",
    "val_dir   = \"/home/ossiemunoz/projects/DL_TP3/dataset_emociones/validation\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset   = datasets.ImageFolder(val_dir,   transform=val_transforms)\n",
    "\n",
    "# ===========================\n",
    "# DATALOADERS\n",
    "# ===========================\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "\n",
    "# Clases para referencia\n",
    "class_names = train_dataset.classes\n",
    "print(\"Clases:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c8953",
   "metadata": {},
   "source": [
    "### Conclusiones preliminares del preprocesamiento:\n",
    "\n",
    "Para mejorar la capacidad de generalización del modelo, incorporamos data augmentation controlado, limitado a transformaciones que no alteran la expresión facial:\n",
    "- Rotaciones leves (≤10°), \n",
    "- RandomHorizontalFlip y \n",
    "- Variaciones moderadas de brillo/contraste. \n",
    "\n",
    "Evitamos transformaciones agresivas que podrían modificar la percepción de la emoción (rotación vertical, deformaciones geométricas grandes o cambios extremos de color).\n",
    "\n",
    "Finalmente, se inspeccionó la distribución por clase para evaluar posibles desbalances. En caso de ser necesario, se prevé el uso de class weights o un WeightedRandomSampler para compensar diferencias significativas entre categorías.\n",
    "\n",
    "Con este pipeline de preprocesamiento se garantiza que el modelo reciba entradas estandarizadas, robustas ante variaciones naturales del dominio y compatibles con imágenes externas que se utilizarán para validar su desempeño final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b754cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS universales\n",
    "\n",
    "# Detectamos si estamos en Google Colab\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab  \n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_colab():\n",
    "    from google.colab import drive  \n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    DATA_DIR = \"/content/drive/MyDrive/DL_TP2\"\n",
    "    ENV = \"Colab\"\n",
    "else:\n",
    "    # Ruta local en el entorno VSC/WSL\n",
    "    DATA_DIR = \"/home/ossiemunoz/projects/DL_TP2\"\n",
    "    ENV = \"Local (VSC/WSL)\"\n",
    "\n",
    "print(f\"Entorno detectado: {ENV}\")\n",
    "print(f\"DATA_DIR = {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e74625",
   "metadata": {},
   "source": [
    "# Punto A - Análisis exploratorio de los datasets\n",
    "- Realizar un EDA apoyado en gráficas adecuadas y coherentes para el caso de estudio.\n",
    "- Analizar detalladamente los valores únicos de cada variable categórica e identificar su nivel de cardinalidad.\n",
    "- Justificar de manera detallada el tipo de transformación que se le asignará a cada variable, en especial a las categóricas. **Dependiendo de su cardinalidad, su contexto y/o lógica interna de orden**, podrán transformarse mediante label/ordinal encoding, one-hot encoding o mediante una capa de embeddings dentro del modelo.\n",
    "- No es necesario aplicar la misma transformación para todas las variables categóricas. El dataset puede (y debe) incluir diferentes tipos de transformaciones según las características de cada variable.\n",
    "- Redactar explícitamente la decisión final adoptada para cada variable y su justificación correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b35da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Análisis exploratotio del dataset: Cargar datasets de entrenamiento y validación según paths universales\n",
    "\n",
    "train_path = os.path.join(DATA_DIR, \"adult_train.csv\")\n",
    "val_path   = os.path.join(DATA_DIR, \"adult_val.csv\")\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val   = pd.read_csv(val_path)\n",
    "\n",
    "print(df_train.shape, df_val.shape)\n",
    "df_train.info()\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3091f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza básica\n",
    "\n",
    "# 1) Normalizamos target a binario en train y val\n",
    "df_train[\"income\"] = df_train[\"income\"].map({\"<=50K\": 0, \">50K\": 1})\n",
    "df_val[\"income\"]   = df_val[\"income\"].map({\"<=50K\": 0, \">50K\": 1})\n",
    "\n",
    "# 2) Reemplazar '?' por 'Unknown'\n",
    "# En las variables categóricas buscamos detectar valores faltantes codificados como '?', principalmente en 'workclass', 'occupation' y 'native-country' para ambos .csv's (train/val). Estos valores se imputarán explícitamente como una categoría \"Unknown\" para no descartar registros y permitir que el modelo aprenda, en caso de que exista, un patrón asociado a la ausencia de información.”\n",
    "\n",
    "cat_cols = [\n",
    "    \"workclass\", \"education\", \"marital-status\", \"occupation\",\n",
    "    \"relationship\", \"race\", \"sex\", \"native-country\"\n",
    "]\n",
    "missing_stats = []\n",
    "\n",
    "n_train = len(df_train)\n",
    "n_val   = len(df_val)\n",
    "\n",
    "for col in cat_cols:\n",
    "    train_q = (df_train[col] == \"?\").sum()\n",
    "    val_q   = (df_val[col] == \"?\").sum()\n",
    "\n",
    "    missing_stats.append({\n",
    "        \"columna\": col,\n",
    "        \"train_?\": train_q,\n",
    "        \"train_%\": train_q / n_train * 100,\n",
    "        \"val_?\": val_q,\n",
    "        \"val_%\": val_q / n_val * 100,\n",
    "    })\n",
    "\n",
    "missing_df = pd.DataFrame(missing_stats)\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f772b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si existe al menos un '?' en features categóricas, lo reemplazamos por 'Unknown'\n",
    "\n",
    "for col in cat_cols:\n",
    "    if (df_train[col] == \"?\").any() or (df_val[col] == \"?\").any():\n",
    "        df_train[col] = df_train[col].replace(\"?\", \"Unknown\")\n",
    "        df_val[col]   = df_val[col].replace(\"?\", \"Unknown\")\n",
    "        print(f\"Reemplazando '?' por 'Unknown' en: {col}\")\n",
    "    else:\n",
    "        print(f\"✔ No se encontraron '?' en: {col}\")\n",
    "\n",
    "print(\"Target normalizado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7ca76",
   "metadata": {},
   "source": [
    "Se verificó la presencia de valores faltantes codificados como '?' en las variables categóricas.\n",
    "En este dataset en particular no se detectaron observaciones, pero se deja implementado el reemplazo automático que recodifica '?' como 'Unknown' en caso de presentarse en futuros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7263b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos la cardinalidad de las variables categóricas (sumatoria de categorías únicas)\n",
    "# Tanto en train como en val, de esta forma podemos ver si existen categorías que sólo aparecen en uno de los conjuntos.\n",
    "# Esto es importante para anticipar problemas en el modelado con embeddings, ya que las categorías que sólo aparecen en val no tendrán embedding entrenado.\n",
    "\n",
    "cat_summary = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    # categorías únicas por conjunto\n",
    "    train_uniques = set(df_train[col].unique())\n",
    "    val_uniques   = set(df_val[col].unique())\n",
    "    total_uniques = train_uniques.union(val_uniques)\n",
    "\n",
    "    cat_summary.append({\n",
    "        \"columna\": col,\n",
    "        \"card_train\": len(train_uniques),\n",
    "        \"card_val\": len(val_uniques),\n",
    "        \"card_total\": len(total_uniques),\n",
    "        \"solo_en_val\": len(val_uniques - train_uniques),\n",
    "        \"solo_en_train\": len(train_uniques - val_uniques),\n",
    "    })\n",
    "\n",
    "cat_card_df = pd.DataFrame(cat_summary).sort_values(\"card_total\", ascending=False)\n",
    "cat_card_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2896430",
   "metadata": {},
   "source": [
    "En la variable de alta cardinalidad native-country se observa una discrepancia menor: el conjunto de entrenamiento contiene 41 categorías, mientras que el conjunto de validación contiene 40.\n",
    "\n",
    "Esta situación no representa un problema para el modelo basado en embeddings, ya que el embedding correspondiente se entrena y simplemente no es utilizado por ninguna muestra de validación.\n",
    "\n",
    "Para el modelo alternativo sin embeddings (one-hot encoding), la categoría presente solo en train generaría una columna que permanecerá en cero en todo el conjunto de validación, aumentando marginalmente la dimensionalidad del vector sin aportar información útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3355c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos cuál es la categoría que aparece en train pero no en val, para 'native-country'. \n",
    "# Todas las demás columnas no presentan categorías exclusivas en ninguno de los dos conjuntos.\n",
    "\n",
    "# Cuál es?\n",
    "train_only = train_uniques - val_uniques\n",
    "train_only = list(train_only)[0]\n",
    "print(f\"Categoría exclusiva de train en 'native-country': {train_only}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50eb729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuántas observaciones tienen esa categoría exclusiva de train?\n",
    "df_train[df_train[\"native-country\"] == train_only].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b1caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuántas de ellas tienen income >50K?\n",
    "df_train[df_train[\"native-country\"] == train_only][\"income\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cfcdd",
   "metadata": {},
   "source": [
    "La categoría Holand-Netherlands dentro de `native-country` posee una única ocurrencia (≈0.003% del dataset) y no está presente en el conjunto de validación. Dado que su aporte estadístico es nulo y únicamente introduce ruido en las representaciones categóricas (embeddings entrenados con un único sample y columnas OHE esparsas), se decidió eliminar dicha observación del conjunto de entrenamiento.\n",
    "\n",
    "Este tratamiento resulta más adecuado que crear una imputación específica para un único registro, manteniendo un espacio categórico más limpio y reduciendo parámetros innecesarios en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194ded1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la decisión de quitar en train esa observación con categoría exclusiva en native-country.\n",
    "\n",
    "rare_countries = train_uniques - val_uniques\n",
    "print(f\"Eliminando observación categoría rara en 'native-country': {rare_countries}\")\n",
    "df_train = df_train[~df_train[\"native-country\"].isin(rare_countries)].reset_index(drop=True)\n",
    "# Dejamos comentada la línea de val, ya que no es necesario aplicarla.\n",
    "# df_val   = df_val[~df_val[\"native-country\"].isin(rare_countries)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bd8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos y clasificamos la cardinalidad de las variables categóricas (sumatoria de categorías únicas)\n",
    "# Tanto en train como en val, y definimos valores únicos > 10 -> \"alta\", entre 6 y 9 \"media\", menor a 6 baja\n",
    "\n",
    "def categorize_cardinality(n_unique):\n",
    "    if n_unique >= 10:\n",
    "        return \"alta\"\n",
    "    elif n_unique >= 6:\n",
    "        return \"media\"\n",
    "    else:\n",
    "        return \"baja\"\n",
    "\n",
    "card_stats = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    train_uniques = set(df_train[col].unique())\n",
    "    val_uniques   = set(df_val[col].unique())\n",
    "    total_uniques = train_uniques.union(val_uniques)\n",
    "\n",
    "    n_train = len(train_uniques)\n",
    "    n_val   = len(val_uniques)\n",
    "    n_total = len(total_uniques)\n",
    "\n",
    "    card_stats.append({\n",
    "        \"columna\": col,\n",
    "        \"card_train\": n_train,\n",
    "        \"card_val\": n_val,\n",
    "        \"card_total\": n_total,\n",
    "        \"cardinalidad\": categorize_cardinality(n_total),\n",
    "        \"solo_en_train\": list(train_uniques - val_uniques),\n",
    "        \"solo_en_val\": list(val_uniques - train_uniques)\n",
    "    })\n",
    "\n",
    "cardinality_df = pd.DataFrame(card_stats).sort_values(\"card_total\", ascending=False)\n",
    "cardinality_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4caf51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teniendo los datasets limpios, analizamos las frecuencias y porcentajes de cada categoría en train y val para todas las variables categóricas.\n",
    "# Esto nos permitirá observar si hay categorías dominantes o muy raras, y comparar su distribución entre ambos conjuntos.\n",
    "\n",
    "# Funciones para análisis y visualización de proporciones de categorías \n",
    "def category_proportions(df_train, df_val, col):\n",
    "    train_counts = df_train[col].value_counts().rename(\"train_count\")\n",
    "    val_counts   = df_val[col].value_counts().rename(\"val_count\")\n",
    "\n",
    "    combined = pd.concat([train_counts, val_counts], axis=1).fillna(0)\n",
    "\n",
    "    combined[\"train_pct\"] = combined[\"train_count\"] / len(df_train) * 100\n",
    "    combined[\"val_pct\"]   = combined[\"val_count\"] / len(df_val) * 100\n",
    "    combined[\"total\"]     = combined[\"train_count\"] + combined[\"val_count\"]\n",
    "    combined[\"total_pct\"] = combined[\"total\"] / (len(df_train) + len(df_val)) * 100\n",
    "\n",
    "    combined = combined.sort_values(\"total\", ascending=False)\n",
    "\n",
    "    return combined\n",
    "\n",
    "def category_proportions_print(df_train, df_val, col):\n",
    "    tbl = category_proportions(df_train, df_val, col).copy()\n",
    "\n",
    "    for c in [\"train_pct\", \"val_pct\", \"total_pct\"]:\n",
    "        tbl[c] = tbl[c].map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "    return tbl\n",
    "\n",
    "def plot_category_distribution(df_train, df_val, col):\n",
    "    combined = category_proportions(df_train, df_val, col)\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(\n",
    "        data=combined.reset_index(),\n",
    "        x=col,\n",
    "        y=\"total_pct\",\n",
    "        order=combined.index\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"% total (train + val)\")\n",
    "    plt.title(f\"Distribución porcentual de '{col}'\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_train_val_comparison(df_train, df_val, col):\n",
    "    combined = category_proportions(df_train, df_val, col).reset_index()\n",
    "\n",
    "    melted = combined.melt(\n",
    "        id_vars=[col],\n",
    "        value_vars=[\"train_pct\", \"val_pct\"],\n",
    "        var_name=\"dataset\",\n",
    "        value_name=\"percentage\"\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(\n",
    "        data=melted,\n",
    "        x=col,\n",
    "        y=\"percentage\",\n",
    "        hue=\"dataset\",\n",
    "        order=combined[col],\n",
    "        palette=\"coolwarm\"\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"%\")\n",
    "    plt.title(f\"Comparación porcentual train vs val en '{col}'\")\n",
    "    plt.legend(title=\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3386cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA de features categóricas completo\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Variable categórica: {col}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Mostrar tabla resumida\n",
    "    display(category_proportions_print(df_train, df_val, col).head(10))\n",
    "\n",
    "    # Gráfico total\n",
    "    plot_category_distribution(df_train, df_val, col)\n",
    "\n",
    "    # Comparación train vs val\n",
    "    plot_train_val_comparison(df_train, df_val, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8981b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos los features numéricos: age, hours-per-week, capital-gain, capital-loss, \n",
    "\n",
    "num_cols = [\"age\", \"hours-per-week\", \"capital-gain\", \"capital-loss\"]\n",
    "\n",
    "# Histogramas de distribución numérica (excepto capital-gain y capital-loss por su alta asimetría)\n",
    "\n",
    "for col in [\"age\", \"hours-per-week\"]:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(df_train[col], bins=40, kde=True)\n",
    "    plt.title(f\"Distribución de {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee10158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capital-gain / capital-loss (skew)\n",
    "\n",
    "for col in [\"capital-gain\", \"capital-loss\"]:\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.histplot(df_train[col], bins=60)\n",
    "    plt.title(f\"{col} (escala original)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Sólo valores >0 (para ver al menos algo)\n",
    "    nonzero = df_train[df_train[col] > 0][col]\n",
    "    if len(nonzero) > 0:\n",
    "        plt.figure(figsize=(7,4))\n",
    "        sns.histplot(nonzero, bins=60)\n",
    "        plt.title(f\"{col} (>0 solamente)\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97310cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % de ceros en capital-gain y capital-loss\n",
    "\n",
    "for col in [\"capital-gain\", \"capital-loss\"]:\n",
    "    pct_zero = (df_train[col] == 0).mean() * 100\n",
    "    print(f\"Feature {col}: {pct_zero:.2f}% de valores son cero\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "842edb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots de features numéricos según income\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.boxplot(x=df_train[\"income\"], y=df_train[col])\n",
    "    plt.title(f\"{col} según income\")\n",
    "    plt.xlabel(\"Income (0 = <=50K, 1 = >50K)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6059cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación de features numéricos vs income\n",
    "\n",
    "corr = df_train[num_cols + [\"income\"]].corr()[\"income\"].sort_values(ascending=False)\n",
    "print(\"Correlación con income:\\n\", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a099091e",
   "metadata": {},
   "source": [
    "## 1. Conclusiones del EDA sobre variables categóricas\n",
    "\n",
    "Se analizaron las siguientes variables categóricas:  \n",
    "`workclass`, `education`, `marital-status`, `occupation`, `relationship`, `race`, `sex`, `native-country`.\n",
    "\n",
    "### 1.1. Cardinalidad y estructura\n",
    "\n",
    "- Se calculó la cardinalidad por variable tanto en `train` como en `val`, verificando además la **cardinalidad total conjunta** y si existían categorías exclusivas de algún conjunto.\n",
    "- El resultado fue:\n",
    "\n",
    "  - **Alta cardinalidad (≥10 categorías)**  \n",
    "    - `education` (~16 categorías)  \n",
    "    - `occupation` (~14 categorías)  \n",
    "    - `native-country` (~40 categorías tras la limpieza)\n",
    "\n",
    "  - **Cardinalidad media (6–9 categorías)**  \n",
    "    - `workclass` (~7 categorías)  \n",
    "    - `marital-status` (~7 categorías)  \n",
    "    - `relationship` (~6 categorías)\n",
    "\n",
    "  - **Cardinalidad baja (≤5 categorías)**  \n",
    "    - `race` (~5 categorías)  \n",
    "    - `sex` (2 categorías)\n",
    "\n",
    "- Se detectó una categoría presente sólo en `train` para `native-country`:\n",
    "  - `Holand-Netherlands`, con **1 sola observación** y sin presencia en `val`.\n",
    "  - Dicha observación correspondía al grupo `<=50K` y representaba ≈0.003 % del dataset.\n",
    "  - Por su frecuencia insignificante y nulo aporte estadístico, se decidió **eliminar esta observación**, evitando:\n",
    "    - un embedding entrenado con un único ejemplo, y  \n",
    "    - una columna OHE completamente dispersa en el modelo sin embeddings.\n",
    "\n",
    "### 1.2. Distribución de categorías y relación con el target\n",
    "\n",
    "- Para cada variable categórica se construyeron tablas de frecuencias y **porcentajes** por categoría, tanto para `train` como para `val`, además de la proporción conjunta.\n",
    "- Se verificó que las distribuciones relativas entre `train` y `val` son consistentes, es decir, no se observan desbalances artificiales introducidos por el split.\n",
    "- Adicionalmente, se calculó la **proporción de ingresos >50K por categoría** (`P(income = 1 | categoría)`), lo que permitió:\n",
    "  - identificar categorías fuertemente asociadas a ingresos altos, por ejemplo, ciertas ocupaciones (`Exec-managerial`, `Prof-specialty`), estados civiles (p.ej. `Married-civ-spouse`) o determinadas combinaciones de `relationship`;\n",
    "  - detectar categorías con tasas muy bajas de >50K (por ejemplo, `Never-married` o ciertos tipos de `workclass`).\n",
    "\n",
    "Este análisis refuerza la idea de que las variables categóricas contienen una señal fuerte y estructurada respecto del target, pero con patrones **no triviales** que justifican el uso de **embeddings** en las de mayor cardinalidad.\n",
    "\n",
    "### 1.3. Decisiones preliminares de transformación categórica\n",
    "\n",
    "A partir del EDA de cardinalidad, distribución y contexto semántico:\n",
    "\n",
    "- `education`  \n",
    "  - Tiene una estructura claramente **ordinal** (niveles educativos crecientes).  \n",
    "  - Se decidió utilizar **ordinal encoding**, preservando el orden lógico de la variable.\n",
    "\n",
    "- `occupation`  \n",
    "  - Cardinalidad media-alta (~14), con categorías heterogéneas pero con posibles similitudes (p.ej. profesiones de alto nivel, trabajos de servicios, etc.).  \n",
    "  - Recomendación: representarla mediante una **capa de embeddings**, permitiendo que el modelo aprenda relaciones latentes entre ocupaciones.\n",
    "\n",
    "- `native-country`  \n",
    "  - Cardinalidad alta (~40) y fuerte dominancia de `United-States`, pero con un conjunto largo de países de menor frecuencia.  \n",
    "  - OHE generaría muchas dimensionalidad con bajo soporte estadístico.  \n",
    "  - Recomendación: utilizar **embeddings** para esta variable.\n",
    "\n",
    "- `workclass`, `marital-status`, `relationship`, `race`  \n",
    "  - Cardinalidad baja/media (5–7), sin estructura de orden natural.  \n",
    "  - Recomendación: **one-hot encoding (OHE)**.\n",
    "\n",
    "- `sex`  \n",
    "  - Variable binaria.  \n",
    "  - Recomendación: **codificación 0/1** (label encoding simple).\n",
    "\n",
    "Estas decisiones las implementaremos en el pipeline de Feature Engineering previo al modelo del punto 2.\n",
    "\n",
    "\n",
    "## 2. Conclusiones del EDA sobre variables numéricas\n",
    "\n",
    "Se analizaron las variables numéricas:\n",
    "\n",
    "- `age`\n",
    "- `hours-per-week`\n",
    "- `capital-gain`\n",
    "- `capital-loss`\n",
    "\n",
    "(Además, `income` fue mapeada a 0/1 y se utilizó como target.)\n",
    "\n",
    "### 2.1. Distribuciones y outliers\n",
    "\n",
    "- **Age**  \n",
    "  - Distribución ligeramente asimétrica hacia la derecha, con mayor concentración en el rango 20–50 años.  \n",
    "  - El boxplot por `income` muestra que el grupo >50K tiende a tener edades mayores.  \n",
    "  - Se observan outliers en los extremos superiores, esperables en una muestra grande de población (personas de edad avanzada aún activas laboralmente).\n",
    "\n",
    "- **Hours-per-week**  \n",
    "  - Distribución con un pico muy marcado en 40 horas semanales.  \n",
    "  - Existen valores extremos (60–90 horas), que aparecen como numerosos “outliers” en el boxplot, pero son plausibles desde el punto de vista laboral.  \n",
    "  - El grupo >50K tiende a trabajar más horas en promedio.\n",
    "\n",
    "- **Capital-gain** y **capital-loss**  \n",
    "  - Ambos presentan distribuciones extremadamente **sesgadas**:\n",
    "    - `capital-gain`: más del ~90 % de los valores son 0.  \n",
    "    - `capital-loss`: más del ~95 % de los valores son 0.\n",
    "  - Los pocos valores positivos son muy grandes, generando colas largas y boxplots dominados por outliers.\n",
    "  - La información relevante no está en la magnitud cruda, sino en:\n",
    "    - el hecho de tener o no ganancias/pérdidas de capital, y  \n",
    "    - el orden de magnitud cuando las hay.\n",
    "\n",
    "No se eliminarán outliers en estas variables, ya que reflejan comportamientos reales en la población y se manejarán mediante transformaciones adecuadas.\n",
    "\n",
    "### 2.2. Correlación con el target\n",
    "\n",
    "La correlación de Pearson entre las variables numéricas y `income` (0/1) fue:\n",
    "\n",
    "- `age`: ~0.24  \n",
    "- `hours-per-week`: ~0.23  \n",
    "- `capital-gain`: ~0.22  \n",
    "- `capital-loss`: ~0.15  \n",
    "\n",
    "Si bien ninguna variable presenta una correlación lineal extremadamente alta con el target, todas muestran una **señal moderada** y complementaria. En particular:\n",
    "\n",
    "- `age`, `hours-per-week` y `capital-gain` muestran la relación positiva más clara con `income`.\n",
    "- `capital-loss` aporta algo de información, pero con fuerza menor.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Implicancias para el Feature Engineering y el modelo con embeddings\n",
    "\n",
    "A partir del EDA categórico y numérico, se define el siguiente esquema de Feature Engineering, orientado específicamente al entrenamiento de un **modelo MLP con embeddings** para clasificación binaria.\n",
    "\n",
    "### 3.1. Transformaciones propuestas por variable\n",
    "\n",
    "| Variable          | Tipo         | Características clave                  | Transformación propuesta                                  |\n",
    "|-------------------|-------------|----------------------------------------|-----------------------------------------------------------|\n",
    "| age               | Numérica    | Rango amplio, ligera asimetría        | `StandardScaler`                                          |\n",
    "| hours-per-week    | Numérica    | Pico en 40h, valores altos plausibles | `StandardScaler`                                          |\n",
    "| capital-gain      | Numérica    | >90% ceros, skew extremo              | `log1p`, variable binaria `(>0)`, luego escalado         |\n",
    "| capital-loss      | Numérica    | >95% ceros, skew extremo              | `log1p`, variable binaria `(>0)`, luego escalado         |\n",
    "| education         | Categórica  | Alta cardinalidad, orden natural      | **Ordinal encoding**                                      |\n",
    "| occupation        | Categórica  | Cardinalidad media-alta (~14)         | **Embedding**                                             |\n",
    "| native-country    | Categórica  | Cardinalidad alta (~40)               | **Embedding**                                             |\n",
    "| workclass         | Categórica  | Cardinalidad media (7)                | **One-Hot Encoding**                                      |\n",
    "| marital-status    | Categórica  | Cardinalidad media (7)                | **One-Hot Encoding**                                      |\n",
    "| relationship      | Categórica  | Cardinalidad media (6)                | **One-Hot Encoding**                                      |\n",
    "| race              | Categórica  | Cardinalidad baja (5)                 | **One-Hot Encoding**                                      |\n",
    "| sex               | Categórica  | Binaria                               | Codificación 0/1                                          |\n",
    "| income            | Target      | Binaria (<=50K / >50K)                | Mapeada a 0/1 (se utilizará Binary Cross Entropy Loss)   |\n",
    "\n",
    "Esta propuesta de FE combina distintas estrategias de codificación, tal como solicita la consigna, y cada decisión está justificada a partir de las distribuciones observadas, la cardinalidad y la semántica de las variables.\n",
    "\n",
    "### 3.2. Lineamientos para el modelo con embeddings\n",
    "\n",
    "A partir del Feature Engineering propuesto, el modelo con embeddings se diseñará siguiendo estas pautas:\n",
    "\n",
    "- **Variables con embeddings**:  \n",
    "  - `occupation` y `native-country` se representarán con capas de embedding separadas.  \n",
    "  - La dimensión de cada embedding se definirá en función de la cardinalidad (por ejemplo, usando heurísticas del tipo `d ≈ min(16, round(k^0.5))`, donde `k` es el número de categorías), o reglas similares debidamente fundamentadas.\n",
    "\n",
    "- **Resto de inputs**:  \n",
    "  - Variables numéricas escaladas (`age`, `hours-per-week`, versiones logarítmicas de gain/loss + indicadores binarios).  \n",
    "  - Variables categóricas codificadas con OHE y codificación ordinal.\n",
    "\n",
    "- **Arquitectura MLP**:  \n",
    "  - Concatenación de todos los embeddings + features numéricos + OHE en un único vector de entrada.  \n",
    "  - Varias capas densas (número de capas y neuronas a definir), con funciones de activación no lineales (por ejemplo, ReLU).  \n",
    "  - Inclusión de **dropout** en las capas ocultas para reducir sobreajuste.\n",
    "\n",
    "- **Función de costo y optimizador**:  \n",
    "  - El problema es de **clasificación binaria**, por lo que se utilizará **Binary Cross Entropy** (idealmente `BCEWithLogitsLoss` en PyTorch).  \n",
    "  - El optimizador será **Adam** (o alguna de sus variantes), tal como indica la consigna.\n",
    "\n",
    "- **Métricas y evaluación**:  \n",
    "  - Durante el entrenamiento se registrarán curvas de:\n",
    "    - **accuracy vs epoch**  \n",
    "    - **F1 macro vs epoch**  \n",
    "    tanto para `train` como para `val`.\n",
    "  - Al finalizar el entrenamiento se reportará:\n",
    "    - **classification report** de `sklearn` (precision, recall, F1 por clase).  \n",
    "    - **matriz de confusión absoluta** y **matriz de confusión normalizada por fila** sobre el conjunto de validación.\n",
    "\n",
    "Con estos planteos cerramos el bloque de EDA y preparamos el Feature Engineering para la implementación del modelo con embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a72bf",
   "metadata": {},
   "source": [
    "# Punto B - Diseño y entrenamiento de un modelo con embeddings\n",
    "- Implementar las transformaciones definidas en el punto anterior e incorporarlas al flujo de entrenamiento.\n",
    "- El modelo debe incluir, como mínimo, una capa de embedding para representar alguna de las variables categóricas.\n",
    "- La elección de la dimensión del o los embeddings queda a criterio del estudiante, pero debe estar correctamente fundamentada. Recuerden que no es obligatorio que todos los embeddings tengan la misma dimensión.\n",
    "- La configuración arquitectónica (número de capas, neuronas por capa, función de activación) es de libre elección.\n",
    "- Incluir dropout en las capas ocultas de la red.\n",
    "- Utilizar Adam o alguna de sus variantes como optimizador.\n",
    "- Seleccionar la función de costo apropiada entre Binary CrossEntropyLoss o Categorical CrossEntropyLoss, según la formulación del problema.\n",
    "- Mostrar las curvas de accuracy vs epoch y F1 macro vs epoch para los sets de entrenamiento y validación.\n",
    "- Presentar un classification report generado con sklearn.\n",
    "- Presentar una matriz de confusión absoluta y otra normalizada por fila, correspondientes al set de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea402472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering propuesto tras el análisis y plateo post-EDA\n",
    "\n",
    "# Clasificamos features según el análisis exploratorio para el tratamiento previo antes del modelado\n",
    "# Numéricas\n",
    "num_raw = [\"age\", \"hours-per-week\", \"capital-gain\", \"capital-loss\"]\n",
    "\n",
    "# Categóricas\n",
    "high_card_embed = [\"occupation\", \"native-country\"]   # embeddings\n",
    "ordinal_cols    = [\"education\"]                     # ordinal\n",
    "ohe_cols         = [\"workclass\", \"marital-status\", \"relationship\", \"race\"]\n",
    "binary_cols      = [\"sex\"]                          # label encoding simple (0/1)\n",
    "target_col       = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b179483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orden de niveles educativos presente en Adult para encoding ordinal\n",
    "# El orden lo basamos en el US Census Bureau. Educational Attainment in the United States: 1994.\n",
    "# (El Census Bureau define explícitamente la escala desde Preschool → Doctorate.)\n",
    "\n",
    "# Definimos\n",
    "education_order = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Some-college\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Prof-school\",\n",
    "    \"Doctorate\"\n",
    "]\n",
    "\n",
    "# Mapeamos educación a valores ordinales\n",
    "education_mapping = {cat: i for i, cat in enumerate(education_order)}\n",
    "education_mapping\n",
    "\n",
    "# Aplicamos el mapeo ordinal a train y val\n",
    "df_train[\"education_ord\"] = df_train[\"education\"].map(education_mapping)\n",
    "df_val[\"education_ord\"]   = df_val[\"education\"].map(education_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bbe8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos log1p y columnas binarias para gain/loss\n",
    "\n",
    "# Columnas binarias (tiene o no tiene gain/loss)\n",
    "df_train[\"has_capital_gain\"] = (df_train[\"capital-gain\"] > 0).astype(int)\n",
    "df_val[\"has_capital_gain\"]   = (df_val[\"capital-gain\"] > 0).astype(int)\n",
    "\n",
    "df_train[\"has_capital_loss\"] = (df_train[\"capital-loss\"] > 0).astype(int)\n",
    "df_val[\"has_capital_loss\"]   = (df_val[\"capital-loss\"] > 0).astype(int)\n",
    "\n",
    "# Aplicamos la transformación logarítmica\n",
    "df_train[\"capital_gain_log\"] = np.log1p(df_train[\"capital-gain\"])\n",
    "df_val[\"capital_gain_log\"]   = np.log1p(df_val[\"capital-gain\"])\n",
    "\n",
    "df_train[\"capital_loss_log\"] = np.log1p(df_train[\"capital-loss\"])\n",
    "df_val[\"capital_loss_log\"]   = np.log1p(df_val[\"capital-loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea445c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding para 'sex' en train y val\n",
    "# Female/Male → 0/1\n",
    "df_train[\"sex_bin\"] = df_train[\"sex\"].map({\"Female\": 0, \"Male\": 1})\n",
    "df_val[\"sex_bin\"]   = df_val[\"sex\"].map({\"Female\": 0, \"Male\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2950b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'workclass', 'marital-status', 'relationship', 'race': OHE (One-Hot Encoding)\n",
    "\n",
    "ohe_train = pd.get_dummies(df_train[ohe_cols], prefix=ohe_cols)\n",
    "ohe_val   = pd.get_dummies(df_val[ohe_cols],   prefix=ohe_cols)\n",
    "\n",
    "# A pesar de haber analizado que tanto train como val tienen igualdad de categorías en estos 4 features, es decir, no hay diferencias, alineamos las columnas por buena práctica y para, en caso que ocurra, evitar mismatch\n",
    "ohe_train, ohe_val = ohe_train.align(ohe_val, join=\"left\", axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de4ad9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación final de features numéricos escalados\n",
    "\n",
    "num_final = [\n",
    "    \"age\",\n",
    "    \"hours-per-week\",\n",
    "    \"capital_gain_log\",\n",
    "    \"capital_loss_log\",\n",
    "    \"has_capital_gain\",\n",
    "    \"has_capital_loss\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_train_scaled = scaler.fit_transform(df_train[num_final])\n",
    "df_val_scaled   = scaler.transform(df_val[num_final])\n",
    "\n",
    "df_train_scaled = pd.DataFrame(df_train_scaled, columns=num_final, index=df_train.index)\n",
    "df_val_scaled   = pd.DataFrame(df_val_scaled,   columns=num_final, index=df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab63842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos las categorías finales para embeddings\n",
    "\n",
    "# Vocabularios para embeddings\n",
    "embed_vocabs = {}\n",
    "\n",
    "for col in high_card_embed:\n",
    "    cats = sorted(df_train[col].unique())\n",
    "    embed_vocabs[col] = {cat: i for i, cat in enumerate(cats)}\n",
    "\n",
    "embed_vocabs\n",
    "\n",
    "# Mapeamos los índices enteros en train y val\n",
    "for col in high_card_embed:\n",
    "    df_train[f\"{col}_idx\"] = df_train[col].map(embed_vocabs[col]).astype(int)\n",
    "    df_val[f\"{col}_idx\"]   = df_val[col].map(embed_vocabs[col]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89934974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos los datasets finales para modelado co Pytorch\n",
    "\n",
    "# Numéricos\n",
    "X_train_num = df_train_scaled\n",
    "\n",
    "# OHE\n",
    "X_train_ohe = ohe_train\n",
    "\n",
    "# Ordinal\n",
    "X_train_ord = df_train[[\"education_ord\"]]\n",
    "\n",
    "# Binary\n",
    "X_train_bin = df_train[[\"sex_bin\"]]\n",
    "\n",
    "# Embedding indices\n",
    "X_train_emb = df_train[[f\"{col}_idx\" for col in high_card_embed]]\n",
    "\n",
    "# Concatenación final para MLP\n",
    "X_train_full = pd.concat(\n",
    "    [X_train_num, X_train_ohe, X_train_ord, X_train_bin, X_train_emb], axis=1\n",
    ")\n",
    "\n",
    "# El Target\n",
    "y_train = df_train[target_col].astype(int)\n",
    "\n",
    "# Aplicamos lo mismo para val\n",
    "X_val_num = df_val_scaled\n",
    "X_val_ohe = ohe_val\n",
    "X_val_ord = df_val[[\"education_ord\"]]\n",
    "X_val_bin = df_val[[\"sex_bin\"]]\n",
    "X_val_emb = df_val[[f\"{col}_idx\" for col in high_card_embed]]\n",
    "\n",
    "X_val_full = pd.concat(\n",
    "    [X_val_num, X_val_ohe, X_val_ord, X_val_bin, X_val_emb], axis=1\n",
    ")\n",
    "y_val = df_val[target_col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bce94bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeo de salud: vamos a validar que el FE tenga consistencia antes de avanzar al modelado \n",
    "\n",
    "# Visualizamos la distribución de capital-gain y capital-loss antes y después de la transformación log1p\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,8))\n",
    "\n",
    "# capital-gain\n",
    "sns.histplot(df_train[\"capital-gain\"], bins=50, ax=axes[0,0], kde=True)\n",
    "axes[0,0].set_title(\"Original capital-gain\")\n",
    "\n",
    "sns.histplot(df_train[\"capital_gain_log\"], bins=50, ax=axes[0,1], kde=True)\n",
    "axes[0,1].set_title(\"Log1p capital-gain\")\n",
    "\n",
    "# capital-loss\n",
    "sns.histplot(df_train[\"capital-loss\"], bins=50, ax=axes[1,0], kde=True)\n",
    "axes[1,0].set_title(\"Original capital-loss\")\n",
    "\n",
    "sns.histplot(df_train[\"capital_loss_log\"], bins=50, ax=axes[1,1], kde=True)\n",
    "axes[1,1].set_title(\"Log1p capital-loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cac3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos boxplots de las variables numéricas escaladas para verificar la estandarización\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(data=df_train_scaled)\n",
    "plt.title(\"Boxplot de variables numéricas escaladas\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83d63475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación entre variables numéricas ya transformadas\n",
    "\n",
    "corr = df_train_scaled.corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlación entre numéricas ya transformadas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79d8787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos las nuevas columnas binarias has_capital_gain y has_capital_loss para verificar su distribución\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "sns.countplot(x=df_train[\"has_capital_gain\"], ax=axes[0])\n",
    "axes[0].set_title(\"has_capital_gain\")\n",
    "\n",
    "sns.countplot(x=df_train[\"has_capital_loss\"], ax=axes[1])\n",
    "axes[1].set_title(\"has_capital_loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46c22179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la distribución de los índices para embeddings de alta cardinalidad\n",
    "\n",
    "for col in high_card_embed:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    sns.histplot(df_train[f\"{col}_idx\"], bins=50)\n",
    "    plt.title(f\"Distribución de índices para embedding: {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a208a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que no haya NaNs en los datasets finales y mostramos sus shapes\n",
    "\n",
    "print(\"NaNs en train_full:\", X_train_full.isna().sum().sum())\n",
    "print(\"NaNs en val_full:\", X_val_full.isna().sum().sum())\n",
    "\n",
    "print(\"Shape train:\", X_train_full.shape)\n",
    "print(\"Shape val:\", X_val_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b6d0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos los datasets de PyTorch Dataset y DataLoader para entrenamiento y validación\n",
    "\n",
    "# Separamos claramente las features que alimentan directamente al MLP y las que van a embeddings\n",
    "\n",
    "dense_cols = (\n",
    "    list(df_train_scaled.columns)      # num_final\n",
    "    + list(ohe_train.columns)          # OHE\n",
    "    + [\"education_ord\", \"sex_bin\"]     # ordinal + binaria\n",
    ")\n",
    "\n",
    "emb_cols = [\"occupation_idx\", \"native-country_idx\"]\n",
    "\n",
    "print(len(dense_cols), dense_cols[:5])\n",
    "print(emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a1e8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la clase Dataset de PyTorch personalizado\n",
    "\n",
    "class AdultDataset(Dataset):\n",
    "    def __init__(self, df, dense_cols, emb_cols, y):\n",
    "        # Dense features\n",
    "        self.dense = torch.tensor(df[dense_cols].values, dtype=torch.float32)\n",
    "        # Embedding indices\n",
    "        self.emb   = torch.tensor(df[emb_cols].values, dtype=torch.long)\n",
    "        # Target\n",
    "        self.y     = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dense[idx], self.emb[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e47397d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos los datasets y dataloaders\n",
    "\n",
    "# Convertir OHE booleanos a float\n",
    "ohe_train = ohe_train.astype(\"float32\")\n",
    "ohe_val   = ohe_val.astype(\"float32\")\n",
    "\n",
    "train_df_for_model = pd.concat(\n",
    "    [df_train_scaled, ohe_train, df_train[[\"education_ord\", \"sex_bin\"]], \n",
    "     df_train[emb_cols]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "val_df_for_model = pd.concat(\n",
    "    [df_val_scaled, ohe_val, df_val[[\"education_ord\", \"sex_bin\"]],\n",
    "     df_val[emb_cols]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "train_dataset = AdultDataset(train_df_for_model, dense_cols, emb_cols, y_train)\n",
    "val_dataset   = AdultDataset(val_df_for_model,   dense_cols, emb_cols, y_val)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, drop_last=False)\n",
    "\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size,\n",
    "                          shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25ca2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo con embbeddings\n",
    "# Definimos una clase que soporte:\n",
    "#   - uno o más embeddings\n",
    "#   - o ningún embedding (para el modelo full-OHE de la tercera parte)\n",
    "\n",
    "class IncomeModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, n_dense, hidden_dims=[128, 64], dropout=0.3):\n",
    "        \"\"\"\n",
    "        emb_sizes: lista de tuplas (num_categorias, dim_embedding)\n",
    "        n_dense:   número de features sin embeddings\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Embeddings\n",
    "        self.emb_layers = nn.ModuleList(\n",
    "            [nn.Embedding(num_cat, emb_dim) for num_cat, emb_dim in emb_sizes]\n",
    "        )\n",
    "        emb_dim_total = sum(emb_dim for _, emb_dim in emb_sizes)\n",
    "\n",
    "        input_dim = n_dense + emb_dim_total\n",
    "\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))  # salida logit\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, dense_x, emb_x):\n",
    "        \"\"\"\n",
    "        dense_x: (batch_size, n_dense)\n",
    "        emb_x:   (batch_size, n_emb_fields) con índices enteros\n",
    "        \"\"\"\n",
    "        if len(self.emb_layers) > 0:\n",
    "            emb_outs = []\n",
    "            for i, emb in enumerate(self.emb_layers):\n",
    "                emb_outs.append(emb(emb_x[:, i]))\n",
    "            emb_cat = torch.cat(emb_outs, dim=1)\n",
    "            x = torch.cat([dense_x, emb_cat], dim=1)\n",
    "        else:\n",
    "            # modelo sin embeddings\n",
    "            x = dense_x\n",
    "\n",
    "        logits = self.mlp(x).squeeze(1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b691f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los tamaños de embeddings basados en la cardinalidad\n",
    "# Usamos dimensión fija de 8 para ambas variables de alta cardinalidad\n",
    "# Si bien active-country tiene 41 categorías, 12 dimensiones es el valor razonable para evitar overfitting y evitar el desbalance hacia United States (90%+ de las observaciones)\n",
    "\n",
    "emb_sizes = [\n",
    "    (df_train[\"occupation_idx\"].nunique(), 6),\n",
    "    (df_train[\"native-country_idx\"].nunique(), 12),\n",
    "]\n",
    "\n",
    "n_dense = len(dense_cols)\n",
    "\n",
    "model = IncomeModel(emb_sizes=emb_sizes, n_dense=n_dense,\n",
    "                    hidden_dims=[128, 64, 32], dropout=0.15)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05dbd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el device, la función de pérdida y el optimizador Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "pos_weight = torch.tensor([1.5], device=device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) # la adecuada para clasificación binaria\n",
    "# criterion = nn.BCEWithLogitsLoss()   # la adecuada para clasificación binaria\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2909a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el loop de entrenamiento con:\n",
    "#   - Accuracy por época\n",
    "#   - F1 Macro por época\n",
    "#   - Curvas para train/val\n",
    "#   - Evaluación con classification report\n",
    "#   - Matriz de confusión absoluta y normalizada\n",
    "\n",
    "# Accuracy y F1 Macro\n",
    "def compute_metrics(y_true, logits):\n",
    "    \"\"\"\n",
    "    Calcula accuracy y F1 macro.\n",
    "    Acepta tensores o numpy arrays.\n",
    "    Internamente convierte todo a tensores CPU y aplica sigmoid de forma segura.\n",
    "    \"\"\"\n",
    "    # Convertimos a tensores si vienen como numpy\n",
    "    if isinstance(y_true, np.ndarray):\n",
    "        y_true = torch.tensor(y_true)\n",
    "\n",
    "    if isinstance(logits, np.ndarray):\n",
    "        logits = torch.tensor(logits)\n",
    "\n",
    "    # Aseguramos tipos correctos en variables\n",
    "    y_true = y_true.detach().cpu().float()\n",
    "    logits = logits.detach().cpu().float()\n",
    "\n",
    "    # Convertimos logits a probabilidades\n",
    "    probs = torch.sigmoid(logits).numpy()\n",
    "\n",
    "    # Calculamos las predicciones binarias\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    y_true_np = y_true.numpy().astype(int)\n",
    "\n",
    "    # Lsa métricas de desempeño con sklearn\n",
    "    acc = accuracy_score(y_true_np, preds)\n",
    "    f1  = f1_score(y_true_np, preds, average=\"macro\")\n",
    "\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "070b585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop de entrenamiento\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20):\n",
    "    history = {\n",
    "        \"train_acc\": [], \"val_acc\": [],\n",
    "        \"train_f1\": [],  \"val_f1\": [],\n",
    "        \"train_loss\": [], \"val_loss\": [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_logits_all = []\n",
    "        train_y_all = []\n",
    "        \n",
    "        for dense_x, emb_x, y in train_loader:\n",
    "            dense_x = dense_x.to(device)\n",
    "            emb_x   = emb_x.to(device)\n",
    "            y       = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(dense_x, emb_x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            train_logits_all.append(logits)\n",
    "            train_y_all.append(y)\n",
    "\n",
    "        # Métricas train\n",
    "        train_logits_all = torch.cat(train_logits_all)\n",
    "        train_y_all = torch.cat(train_y_all)\n",
    "        train_acc, train_f1 = compute_metrics(train_y_all, train_logits_all)\n",
    "        train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_logits_all = []\n",
    "        val_y_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for dense_x, emb_x, y in val_loader:\n",
    "                dense_x = dense_x.to(device)\n",
    "                emb_x   = emb_x.to(device)\n",
    "                y       = y.to(device)\n",
    "\n",
    "                logits = model(dense_x, emb_x)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "                val_losses.append(loss.item())\n",
    "                val_logits_all.append(logits)\n",
    "                val_y_all.append(y)\n",
    "\n",
    "        # Métricas val\n",
    "        val_logits_all = torch.cat(val_logits_all)\n",
    "        val_y_all = torch.cat(val_y_all)\n",
    "        val_acc, val_f1 = compute_metrics(val_y_all, val_logits_all)\n",
    "        val_loss = sum(val_losses) / len(val_losses)\n",
    "\n",
    "        # Guardamos el historial\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "        history[\"val_f1\"].append(val_f1)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Loss: {train_loss:.4f}/{val_loss:.4f} - \"\n",
    "              f\"Acc: {train_acc:.4f}/{val_acc:.4f} - \"\n",
    "              f\"F1: {train_f1:.4f}/{val_f1:.4f}\")\n",
    "\n",
    "    return history, (val_logits_all, val_y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28d8675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo para 50 épocas\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "history, (val_logits, val_y) = train_model(\n",
    "    model, train_loader, val_loader,\n",
    "    criterion, optimizer,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91d04cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_emb = history.copy\n",
    "logits_emb = val_logits\n",
    "y_emb = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cfca33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de accuracy y F1 macro vs epoch para los sets de entrenamiento y validación.\n",
    "\n",
    "# Curva de Accuracy\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history[\"train_acc\"], label=\"Train Accuracy\")\n",
    "plt.plot(history[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.title(\"Accuracy por Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# Curva de F1 Macro\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history[\"train_f1\"], label=\"Train F1 Macro\")\n",
    "plt.plot(history[\"val_f1\"], label=\"Val F1 Macro\")\n",
    "plt.title(\"F1 Macro por Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Macro\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5abbb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "\n",
    "probs = torch.sigmoid(val_logits).cpu().numpy()\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "true  = val_y.cpu().numpy()\n",
    "\n",
    "print(\"\\n CLASSIFICATION REPORT (CON EMBEDDINGS) \\n\")\n",
    "print(classification_report(true, preds, target_names=[\"<=50K\", \">50K\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a43015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "\n",
    "cm = confusion_matrix(true, preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Pred <=50K\", \"Pred >50K\"],\n",
    "            yticklabels=[\"True <=50K\", \"True >50K\"])\n",
    "plt.title(\"Matriz de confusión (absoluta)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd4c8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión normalizada por fila\n",
    "\n",
    "cm_norm = confusion_matrix(true, preds, normalize=\"true\")\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Pred <=50K\", \"Pred >50K\"],\n",
    "            yticklabels=[\"True <=50K\", \"True >50K\"])\n",
    "plt.title(\"Matriz de confusión (normalizada)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39ec282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter para modelo CON embeddings\n",
    "\n",
    "# Aseguramos tensores CPU + probabilidades\n",
    "probs_emb = torch.sigmoid(val_logits).detach().cpu().numpy()\n",
    "y_true_emb = val_y.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Jitter para dispersar puntos verticalmente\n",
    "x_jitter = y_true_emb + (np.random.randn(len(y_true_emb)) * 0.02)\n",
    "\n",
    "plt.scatter(\n",
    "    x_jitter,\n",
    "    probs_emb,\n",
    "    alpha=0.15,\n",
    "    s=20\n",
    ")\n",
    "\n",
    "plt.axhline(0.5, color=\"red\", linestyle=\"--\", linewidth=1.2)\n",
    "\n",
    "plt.xlabel(\"Valor real (0 = <=50K, 1 = >50K)\")\n",
    "plt.ylabel(\"Probabilidad predicha (>50K)\")\n",
    "plt.title(\"Scatter Real vs Predicho — Modelo con Embeddings\")\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.xlim([-0.2, 1.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3083d",
   "metadata": {},
   "source": [
    "# Modelo con Embeddings - Análisis, Resultados y Conclusiones\n",
    "\n",
    "### Contexto:\n",
    "El objetivo de esta parte siguiendo la consigna fue entrenar un modelo de clasificación binaria (<=50K vs >50K) utilizando embeddings para las variables categóricas de alta cardinalidad.\n",
    "\n",
    "Las variables transformadas mediante embeddings fueron:\n",
    "    - occupation (14 categorías)\n",
    "    - native-country (41 categorías)\n",
    "\n",
    "El resto de las variables categóricas se codificaron con OHE u ordinal encoding según el caso y justificaciones ya mencionadas.\n",
    "\n",
    "### Arquitectura del modelo y estrategia de búsqueda\n",
    "\n",
    "El proceso de modelado se estructuró en dos etapas claramente separadas:\n",
    "\n",
    "1) Ajuste de la arquitectura base del MLP (antes de tocar tamaño de embeddings)\n",
    "Se experimentó primero con los hiperparámetros del cuerpo denso del modelo:\n",
    "- Capas ocultas: se probaron configuraciones\n",
    "    - 128 → 64\n",
    "    - 128 → 64 → 32\n",
    "- Dropout: se ajustó entre 0.30 → 0.15, buscando balance entre underfitting/overfitting.\n",
    "- pos_weight: se calibró en el rango 1.3–1.6 para compensar el desbalance.\n",
    "- batch_size: se probaron 512 → 128, favoreciendo una señal de gradiente más estable.\n",
    "- Épocas: 100 → 70 → 50, evaluando convergencia vs. sobreajuste.\n",
    "- Optimizador: Adam, función de activación ReLU, Loss BCEWithLogitsLoss.\n",
    "\n",
    "Esta etapa sirvió para fijar una arquitectura estable, convergente y comparativamente robusta.\n",
    "Recién cuando estuvo firme, pasamos a la etapa 2.\n",
    "\n",
    "2) Ajuste del tamaño de los embeddings\n",
    "Con la arquitectura consolidada, se testeó la sensibilidad del modelo al tamaño de cada embedding:\n",
    "- occupation_idx: 8 → 6\n",
    "- native_country_idx: 8 → 10 → 12\n",
    "\n",
    "Este fine tuning permitió explorar si un embedding más comprimido mejoraba la generalización en categorías ruidosas y si un embedding más amplio capturaba mejor la alta cardinalidad del país de origen.\n",
    "\n",
    "#### Evolución del tuning de embeddings\n",
    "\n",
    "Se realizaron cuatro ejecuciones principales con variaciones en los tamaños de embedding:\n",
    "\n",
    "| Ejecución     | occupation_emb | native_country_emb | F1 (>50K) | Recall (>50K) | Macro F1 |\n",
    "|---------------|:----------------:|:--------------------:|:-----------:|:----------------:|:----------:|\n",
    "| Exec 1        | 8              | 8                  | 0.66      | 0.58–0.63      | 0.78     |\n",
    "| Exec 2        | 6              | 10                 | 0.67      | ~0.70          | 0.78–0.79|\n",
    "| Exec 3        | 6              | 10                 | 0.68      | ~0.70          | 0.79     |\n",
    "| **Exec Final**| **6**          | **12**             | **0.68**  | **0.72**       | **0.79** |\n",
    "\n",
    "\n",
    "#### Conclusión del tuning\n",
    "- occupation funciona mejor con un embedding más comprimido (6 dimensiones).\n",
    "- native-country mejora ligeramente al subir a 12 dimensiones, pero muestra señales claras de que ese es su “techo natural” antes de introducir ruido o sobreajuste.\n",
    "- La combinación occupation=6 / native-country=12 fue la que produjo mejor recall de la clase minoritaria y curvas más estables.\n",
    "\n",
    "\n",
    "### Curvas de aprendizaje\n",
    "\n",
    "Las curvas de accuracy y F1 macro mostraron:\n",
    "- Convergencia suave, sin picos o saltos pronunciados.\n",
    "- Overfitting bajo debido al dropout del 15% y el pos_weight balanceado.\n",
    "- Mejor estabilidad en validación respecto a versiones anteriores del modelo.\n",
    "- Rendimiento máximo alcanzado muy cerca de la época 30–35 siendo 50 épocas es un buen punto de corte.\n",
    "\n",
    "### Classification Report – Validación\n",
    "\n",
    "| Clase         | Precision | Recall | F1-score | Support |\n",
    "|---------------|:-----------:|:--------:|:----------:|:---------:|\n",
    "| <=50K         | 0.91      | 0.87   | 0.89     | 11360   |\n",
    "| >50K          | 0.65      | 0.72   | 0.68     | 3700    |\n",
    "| **Accuracy**  | —         | —      | **0.84** | **15060** |\n",
    "| **Macro Avg** | 0.78      | 0.80   | 0.79     | 15060   |\n",
    "| **Weighted Avg** | 0.84   | 0.84   | 0.84     | 15060   |\n",
    "\n",
    "\n",
    "- Accuracy ≈ 84% → lo que indica que el modelo logra capturar una parte relevante de la relación entre las variables demográficas y el nivel de ingreso, sin caer en sobreajuste..\n",
    "- F1-score (minoritaria) = 0.68 → sólido para un problema altamente desbalanceado.\n",
    "- Recall(minoritaria) = 0.72 → el mejor obtenido entre todas las configuraciones.\n",
    "- Macro-F1 = 0.79 → buen equilibrio entre clases.\n",
    "\n",
    "## Conclusiones del modelo con embeddings\n",
    "\n",
    "a) Los embeddings demostraron ser la mejor representación para variables con alta cardinalidad y semántica débil, evitando mucha dimensionalidad y capturando relaciones internas no lineales.\n",
    "\n",
    "b) La combinación occupation_idx=6 y native_country_idx=12 fue la más eficaz, logrando el mejor recall para la clase >50K.\n",
    "\n",
    "c) El modelo converge de forma estable, sin sobreajuste fuerte, y mantiene un balance sólido entre todas las métricas relevantes.\n",
    "\n",
    "d) Este modelo queda seleccionado como el “modelo base con embeddings” para la comparación final contra el modelo alternativo sin embeddings + OHE de la parte siguiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb7d09",
   "metadata": {},
   "source": [
    "# Punto C - Diseño y entrenamiento de un modelo sin embeddings\n",
    "\n",
    "- Entrenar un segundo modelo, aplicando one-hot encoding a todas las variables que en el punto b) fueron representadas mediante embeddings.\n",
    "- Mantener exactamente la misma arquitectura del modelo anterior: igual número de capas, mismas neuronas, mismas funciones de activación y la misma probabilidad de dropout.\n",
    "- Presentar las mismas métricas, visualizaciones y reportes que en el modelo con embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ab45179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo sin embeddings (solo OHE), Mantener exactamente la misma arquitectura del modelo con embeddings:\n",
    "# - Capas: 128 → 64 → 32\n",
    "# - Dropout: 0.15\n",
    "# - Optimizador: Adam\n",
    "# - Función de pérdida: BCEWithLogitsLoss(pos_weight)\n",
    "# - Batch_size: 128\n",
    "# - Cantidad de épocas: 50\n",
    "\n",
    "# Variables categóricas: workclass, education, marital-status, occupation, relationship, race, sex, native-country\n",
    "# Las codificamos con OHE clásico\n",
    "\n",
    "# Variables numéricas: age, hours-per-week, capital_gain_log, capital_loss_log, has_capital_gain, has_capital_loss, education_ord, sex_bin\n",
    "# Quedan igual con el FE aplicado para el modelo con embeddings\n",
    "\n",
    "# Income queda con también igual con 0/1 (<=50K / >50K)\n",
    "\n",
    "# Definimos variables categóricas (las mismas que antes)\n",
    "cat_cols = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\"\n",
    "]\n",
    "\n",
    "# Definimos variables numéricas (ídem)\n",
    "num_cols = [\n",
    "    \"age\",\n",
    "    \"hours-per-week\",\n",
    "    \"capital_gain_log\",\n",
    "    \"capital_loss_log\",\n",
    "    \"has_capital_gain\",\n",
    "    \"has_capital_loss\",\n",
    "    \"education_ord\",\n",
    "    \"sex_bin\"\n",
    "]\n",
    "\n",
    "# OHE en train\n",
    "train_noemb = pd.get_dummies(df_train[cat_cols], drop_first=False)\n",
    "train_noemb = pd.concat([df_train[num_cols], train_noemb], axis=1)\n",
    "\n",
    "# OHE en val\n",
    "val_noemb = pd.get_dummies(df_val[cat_cols], drop_first=False)\n",
    "val_noemb = pd.concat([df_val[num_cols], val_noemb], axis=1)\n",
    "\n",
    "# AlineaMOS columnas\n",
    "train_noemb, val_noemb = train_noemb.align(val_noemb, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "# Extraemos targets\n",
    "y_train = df_train[\"income\"].values.astype(\"float32\")\n",
    "y_val = df_val[\"income\"].values.astype(\"float32\")\n",
    "\n",
    "# Aseguramos un solo dtype numérico para todas las columnas\n",
    "train_noemb = train_noemb.astype(\"float32\")\n",
    "val_noemb   = val_noemb.astype(\"float32\")\n",
    "\n",
    "# Convertimos X a tensores\n",
    "X_train = torch.tensor(train_noemb.values, dtype=torch.float32)\n",
    "X_val   = torch.tensor(val_noemb.values,   dtype=torch.float32)\n",
    "\n",
    "# Definimos la dimensión de entrada del MLP sin embeddings\n",
    "input_dim_noemb = X_train.shape[1]\n",
    "input_dim_noemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "708be9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X e y para el modelo sin embeddings (solo features densos + OHE)\n",
    "X_train_noemb = X_train.clone()\n",
    "X_val_noemb   = X_val.clone()\n",
    "\n",
    "y_train_noemb = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_noemb   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "\n",
    "# Dataset\n",
    "train_dataset_noemb = TensorDataset(X_train_noemb, y_train_noemb)\n",
    "val_dataset_noemb   = TensorDataset(X_val_noemb,   y_val_noemb)\n",
    "\n",
    "# DataLoaders (mantenemos batch_size = 128 como en la mejor exec del modelo con embeddings)\n",
    "batch_size = 128\n",
    "\n",
    "train_loader_noemb = DataLoader(\n",
    "    train_dataset_noemb,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "val_loader_noemb = DataLoader(\n",
    "    val_dataset_noemb,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(\"Input dim sin embeddings:\", input_dim_noemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61c1bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la clase del modelo MLP idéntico al anterior, pero sis embeddings\n",
    "\n",
    "class IncomeMLP_NoEmb(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6634dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo sin embeddings\n",
    "\n",
    "model_noemb = IncomeMLP_NoEmb(input_dim_noemb).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor([pos_weight], device=device)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model_noemb.parameters(), lr=1e-3)\n",
    "\n",
    "history_noemb = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"train_f1\": [],\n",
    "    \"val_f1\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train\n",
    "    model_noemb.train()\n",
    "    running_loss = 0.0\n",
    "    all_logits_train = []\n",
    "    all_y_train = []\n",
    "\n",
    "    for X_batch, y_batch in train_loader_noemb:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_noemb(X_batch).squeeze(1)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        all_logits_train.append(logits.detach().cpu())\n",
    "        all_y_train.append(y_batch.detach().cpu())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader_noemb.dataset)\n",
    "    all_logits_train = torch.cat(all_logits_train)\n",
    "    all_y_train = torch.cat(all_y_train)\n",
    "\n",
    "    train_acc, train_f1 = compute_metrics(\n",
    "                        all_y_train,\n",
    "                        all_logits_train\n",
    "    )\n",
    "\n",
    "    # Val\n",
    "    model_noemb.eval()\n",
    "    val_running_loss = 0.0\n",
    "    all_logits_val = []\n",
    "    all_y_val = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader_noemb:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model_noemb(X_batch).squeeze(1)\n",
    "            loss = criterion(logits, y_batch)\n",
    "\n",
    "            val_running_loss += loss.item() * X_batch.size(0)\n",
    "            all_logits_val.append(logits.cpu())\n",
    "            all_y_val.append(y_batch.cpu())\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader_noemb.dataset)\n",
    "    all_logits_val = torch.cat(all_logits_val)\n",
    "    all_y_val = torch.cat(all_y_val)\n",
    "    val_acc, val_f1 = compute_metrics(\n",
    "        all_y_val, all_logits_val\n",
    "    )\n",
    "\n",
    "    history_noemb[\"train_loss\"].append(train_loss)\n",
    "    history_noemb[\"val_loss\"].append(val_loss)\n",
    "    history_noemb[\"train_acc\"].append(train_acc)\n",
    "    history_noemb[\"val_acc\"].append(val_acc)\n",
    "    history_noemb[\"train_f1\"].append(train_f1)\n",
    "    history_noemb[\"val_f1\"].append(val_f1)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{num_epochs} - \"\n",
    "        f\"Loss: {train_loss:.4f}/{val_loss:.4f} - \"\n",
    "        f\"Acc: {train_acc:.4f}/{val_acc:.4f} - \"\n",
    "        f\"F1: {train_f1:.4f}/{val_f1:.4f}\"\n",
    "    )\n",
    "# Guardamos variables para classification report y plots\n",
    "val_logits_noemb = all_logits_val.clone()\n",
    "val_y_noemb      = all_y_val.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f06a0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo sin embeddings - curvas de accuracy y F1 macro vs epoch para los sets de entrenamiento y validación.\n",
    "\n",
    "x = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# Curva de Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, history_noemb[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(x, history_noemb[\"val_acc\"], label=\"Val Acc\")\n",
    "plt.title(\"Accuracy vs Epoch (Sin Embeddings)\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x, history_noemb[\"train_f1\"], label=\"Train F1 Macro\")\n",
    "plt.plot(x, history_noemb[\"val_f1\"], label=\"Val F1 Macro\")\n",
    "plt.title(\"F1 Macro vs Epoch (Sin Embeddings)\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"F1 Macro\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aefc8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "\n",
    "probs_noemb = torch.sigmoid(val_logits_noemb).detach().cpu().numpy()\n",
    "preds_noemb = (probs_noemb >= 0.5).astype(int)\n",
    "y_true_noemb = val_y_noemb.cpu().numpy()\n",
    "\n",
    "print(\"\\n CLASSIFICATION REPORT (SIN EMBEDDINGS) \\n\")\n",
    "print(classification_report(y_true_noemb, preds_noemb, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a31d0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "\n",
    "cm = confusion_matrix(y_true_noemb, preds_noemb)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matriz de Confusión — Modelo sin Embeddings\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf575797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión normalizada por fila\n",
    "\n",
    "cm_norm = confusion_matrix(y_true_noemb, preds_noemb, normalize='true')\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Greens\")\n",
    "plt.title(\"Matriz Normalizada — Modelo sin Embeddings\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb62288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de predicción Vs. real sin embeddings\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(\n",
    "    y_true_noemb + np.random.normal(0, 0.02, size=len(y_true_noemb)),  # jitter eje X\n",
    "    probs_noemb,\n",
    "    alpha=0.25,\n",
    "    s=12\n",
    ")\n",
    "\n",
    "plt.axhline(0.5, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "plt.yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "plt.xlabel(\"Valor real (0 = <=50K, 1 = >50K)\")\n",
    "plt.ylabel(\"Probabilidad predicha (>50K)\")\n",
    "plt.title(\"Scatter Real vs Predicho — Modelo sin Embeddings\")\n",
    "plt.grid(alpha=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8187f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de las diferencias entre modelos (EMB vs. NOEMB)\n",
    "\n",
    "probs_emb   = torch.sigmoid(val_logits).detach().cpu().numpy()\n",
    "probs_noemb = torch.sigmoid(val_logits_noemb).detach().cpu().numpy()\n",
    "\n",
    "diff = np.abs(probs_emb - probs_noemb)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(diff, bins=40, edgecolor=\"k\", alpha=0.7)\n",
    "plt.title(\"Diferencia absoluta de probabilidad\\nEmbeddings vs No Embeddings\")\n",
    "plt.xlabel(\"|p_emb - p_noemb|\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "print(\"Dif media:\", diff.mean())\n",
    "print(\"Dif p90 :\", np.percentile(diff, 90))\n",
    "print(\"Dif max :\", diff.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c328a2",
   "metadata": {},
   "source": [
    "## Tabla comparativa de los 2 modelos, con y sin embeddings\n",
    "\n",
    "### Comparación de desempeño entre modelos\n",
    "\n",
    "| Modelo                 | Accuracy (Val) | F1 Macro (Val) | Loss (Val) |\n",
    "|------------------------|:----------------:|:----------------:|:------------:|\n",
    "| **Con Embeddings**     | 0.8352         | 0.7860         | 0.4523     |\n",
    "| **Sin Embeddings (OHE)** | 0.8445         | 0.7889         | 0.4082     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80577602",
   "metadata": {},
   "source": [
    "## Parte D - Conclusiones y observaciones finales\n",
    "\n",
    "A partir de los resultados obtenidos en ambos enfoques —MLP con embeddings y MLP tradicional con variables categóricas OHE— se pueden sacar algunas conclusiones:\n",
    "\n",
    "1. Desempeño predictivo\n",
    "\n",
    "- En términos de métricas finales, no se observan diferencias significativas entre los dos modelos.\n",
    "    Ambos alcanzan:\n",
    "    - Accuracy ≈ 0.84\n",
    "    - F1 Macro ≈ 0.79\n",
    "    - Un patrón de aprendizaje muy similar a lo largo de las épocas.\n",
    "\n",
    "Podemos decir que ambos modelos tienen desempeños similares, ninguno saca una ventaja clara sobre el otro.\n",
    "\n",
    "2. ¿Por qué los embeddings no dieron una mejora marcada?\n",
    "\n",
    "- Los embeddings suelen distinguirse en desempeño cuando:\n",
    "    - Categorías muy numerosas o tienen una estructura semántica útil.\n",
    "    - Hay dimensionalidad excesiva y el OHE genera mucha cantidad de fratures adicionales.\n",
    "    - Hay interacciones latentes entre categorías.\n",
    "\n",
    "- En este dataset, sin embargo:\n",
    "    - Las columnas categóricas son relativamente chicas (salvo native-country, que igual aporta poco porque el 90% cae en “United-States”).\n",
    "    - El OHE no genera una dimensionalidad elevada, por lo que el MLP sin embeddings no se ve afectado.\n",
    "    - Muchas categorías tienen baja cardinalidad (sex, race, relationship, marital-status…), lo que limita la capacidad de los embeddings para descubrir “relaciones internas” entre ellas.\n",
    "\n",
    "    Resultado en este caso: los embeddings no aprenden nada suficientemente distinto como para superar al OHE tradicional.\n",
    "\n",
    "3. Interpretación del histograma de diferencias\n",
    "\n",
    "- El análisis de diferencias entre probabilidades predichas (modelo con vs sin embeddings) mostró:\n",
    "    - Diferencia media: 0.056 → los modelos predicen muy parecido.\n",
    "    - Percentil 90: 0.15 → incluso en los casos donde divergen, no es sustantivo.\n",
    "    - Picos extremos aislados → algunos outliers donde uno de los modelos diverge un poco más que el otro, pero no afectan la métrica global.\n",
    "\n",
    "    Esto confirma lo anterior: Los dos modelos ven prácticamente lo mismo y toman decisiones casi idénticas.\n",
    "\n",
    "4. ¿Cuál modelo conviene elegir?\n",
    "\n",
    "    Depende más del gusto y el uso que del rendimiento:\n",
    "\n",
    "- Sin embeddings (OHE)\n",
    "    - Más directo\n",
    "    - Menos complejo, más fácil de explicar\n",
    "    - Métricas marginalmente mejores\n",
    "\n",
    "- Con embeddings\n",
    "    - Más elegante\n",
    "    - Más escalable si el día de mañana se agregan más columnas categóricas con alta cardinalidad\n",
    "\n",
    "    Con este dataset, el modelo OHE resulta más simple y alcanza un rendimiento igual o apenas mejor, por lo que termina siendo la mejor opción práctica.\n",
    "\n",
    "5. Conclusión final\n",
    "\n",
    "    Ambos enfoques funcionan bien, pero el modelo sin embeddings termina ganando por puntos, más por simplicidad y estabilidad que por diferencia en performance.\n",
    "    La estructura del dataset favorece a un MLP clásico con OHE: categorías pequeñas, país dominante, y una dimensionalidad que no exige al modelo aprender a representar una variable categórica con menos dimensiones que las que tendría el OHE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-tp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
